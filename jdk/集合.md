# Collection (Queue List Set)
Iterable子类，框架使用模板方法模式，集合的顶级接口
## AbstractCollection
继承Collection，内部变量MAX_ARRAY_SIZE，容量-扩容-没有超过Integer.MAX_VALUE，则Integer.MAX_VALUE-8，否则Integer.MAX_VALUE，目的应该是支持一些虚拟机的header words存储，降低OOM概率
### List
#### AbstractList
提供一些基本方法，内部实现了两种迭代器实现，Itr，ListItr（Itr子类，可以修改、增加元素），内部变量modCount标识结构被修改的次数（大小改变）
##### ArrayList
内部使用Object[]数据存储元数，默认为空数据，使用了transient修饰    
默认第一次扩容大小DEFAULT_CAPACITY为10，最大的容量大小为Integer.MAX_VALUE，代码中尽量大小维持在最大值Integer.MAX_VALUE - 8，每次扩容（除没有加默认容量的第一次）都是原来大小的1.5倍  
内部实现了两种迭代器类似于AbstractList 
内部实现了ArrayListSpliterator   
remove()一个元素需要将元素index后面进行拷贝，相当于坐标向前移动一位，末尾置null  
removeIf()  
记录需要移除的元素坐标，记录到bitSet,使用bitSet的nextClear方法（找到未记录的下一个坐标）将现存的所有元素左移

##### ArrayListSpliterator
Fence第一次使用为size大小，内部使用index进行分割，初始为0。index到fence之间的元素为一个spliterator内容；每次切割从中间切割，index和fence互置

##### bitSet
内部一个long数组存储元素，按需增长的位向量 -> 可扩容，每次扩容大小至少是2倍（如果需要的index大于了两倍值就是index值）
index = N >> 6
每个数组元素可存储 1 << 6 个数
每个元素N通过 1 向左移 N  | 元素值 = 数组值
因为一个数组的元素的差值在 1 << 6之间，而 1 <<6 恰恰又是int的最大为64，所以不可能有两个值位移结果相同，所以可通过 & N 判断是否有该值


##### linketList
内部使用Node链表存储节点，继承了deqeue，实现了双向队列，内部遍历队列使用了折中查询小技巧，判断index与 size >> 1的关系，从head或者last开始查询。
内部同样有一个实现了spliterator的类LLSpliterator
由于是链表无法   内部使用了一个批处理模式来实现split，每次切割定值（size 和 batch取小值）

Spliterators工具类自己实现了一个ArraySpliterator，和ArrayListSpliterator相似，只是存储容器是数据


##### Vector
里面实现和arrayList类似，每次扩容的大小可以自定义，默认是2倍，内部方法都被synchronized修饰，内部实现的VectorSpliterator和ArraySpliterator大致相同

##### Stack 
继承了vector，提供了线程安全的pop、peek方法。

### Queue
单向队列
### AbstractQueue
模板类
#### ConcurrentLinkedQueue 
基于cas的无锁队列，使用对象链表
#### LinkedBlockingQueue 
基于ReentrantLock的有锁队列，使用对象链表,默认大小为Integer.MAX_VALUE
#### ArrayBlockingQueue 
基于ReentrantLock的有锁队列，使用数据存储元素
#### PriorityQueue
数组存储的优先级队列，内部数据结构为二叉树，存储容器为数据，只要是数据就要涉及到扩容，如果容量小于64，每次扩容+2，否则2倍扩容；内部实现的PriorityQueueSpliterator和ArrayListSpliterator类似
#### PriorityBlockingQueue  
基于ReentrantLock的有锁队列，使用数据存储元素，内部结构为二叉树
#### DelayQueue 
基于PriorityQueue（无锁）和ReentrantLock的实现有锁队列，存储内容需实现Delayed接口
#### SynchronousQueue 
一个生产、消费队列，但是内部并没有容器存储元素，生产、消费无法消费、生产元素时对应线程会堵塞
内部有两个模型，分别实现方式为队列和栈.
公平模式：内部使用head、tail实现队列存储元素：插入一个元素被park，poll一个元素unpark元素对应线程，每次都是从head.next取节点
非公平模式：内部使用栈
通过使用了SynchronousQueue实现了cacheThreadPool，offer(),poll()不堵塞(线程池获取任务核心线程take 额外poll)，创建了一个核心线程为0，最大线程为Integer.MAX_VALUE的线程池，默认队列实现为非公平
每次添加任务如果有空闲线程直接运行，否则会加入队列失败，创建一个线程执行

### Deque
双向队列
#### ArrayDeque
容器使用数组，每次两倍扩容；带有大小的构造参数时，实际的数据大小并不一定等于参数大小，最小8
#### ConcurrentLinkedDeque
#### LinkedBlockingDeque

### Set
#### hashSet
内部有个hashMap或者linkedHashMap实现的HashMap变量，存储元素存到hashMap里面，key为值，value为PRESENT常量

#### LinkedHashMap
继承HashMap
内部entry增加after、before属性,在new Node时指向tail或者head；内部新增head、tail变量
内部变量accessOrder控制顺序规则，true为访问的顺序，false为put顺序，默认false
重写了afterNodeAccess方法，对入参e设置为tail
重写了afterNodeInsertion（在添加节点时是否移除head）、afterNodeRemoval(在节点移除时更改对应的after、before指针)
其他改动：迭代器实现方式改变，使用了head、tail、after、before指针实现；

## Map
#### HashMap

内部类 Node链表节点，treeNode树节点
默认大小为16，大小必须是2的power,(在定位hash index时 相当于截取hash值低位码，因为length-1全是1)
常量：最大容量、默认负载因子（默认0.75）、转换红黑树临界值（默认8）、红黑树节点resize临界值（默认6）、调整红黑树是最小容量（默认64，如果小于该值进行resize）
变量：threshold（下一次resize大小，capacity * load factor），负载因子

##### hash算法
key的hash值 ^ (key的hash值 >> 16) => 扰动函数 高低位异或（int32位，增加随机性）
定位：hash值 & (capicity - 1)  

##### Resize
初始化或者扩容算法，每次2倍扩容。每个节点resize：如果该节点只有一个元素，直接根据新容量重新定位，如果有后继节点，1.链表：将链表分为高位和低位（根据hash值 & old capicity 判断，因为新的容量是old容量的2倍且都是2的power,old capicity & (new capicity - 1) = 1，如果 = 0不需要改变index，否则位移old capicity），本质上相当于了一次rehash 2.树节点：  split()
##### 其他细节：

hash冲突是符合泊松分布的，冲突概率最小的是在7-8之间，因为经过计算，在 hash 函数设计合理的情况下，发生 hash 碰撞 8 次的几率为百万分之 6，概率说话。。因为 8 够用了，至于为什么转回来是 6，因为如果 hash 碰撞次数在 8 附近徘徊，会一直发生链表和红黑树的转化，为了预防这种情况的发生。

##### 1.8与1.7的区别
Hash函数优化，只位移一次
数组+链表改成了数组+链表或红黑树；
链表的插入方式从头插法改成了尾插法，简单说就是插入时，如果数组位置上已经有元素，1.7 将新元素放到数组中，原始节点作为新节点的后继节点，1.8 遍历链表，将元素放置到链表的最后；
扩容的时候 1.7 需要对原数组中的元素进行重新 hash 定位在新数组的位置，1.8 采用更简单的判断逻辑，位置不变或索引+旧容量大小；
在插入时，1.7 先判断是否需要扩容，再插入，1.8 先进行插入，插入完成再判断是否需要扩容

#### LinkedHashMap
继承HashMap
内部entry增加after、before属性,在new Node时指向tail或者head；内部新增head、tail变量
内部变量accessOrder控制顺序规则，true为访问的顺序，false为put顺序，默认false
重写了afterNodeAccess方法，对入参e设置为tail
重写了afterNodeInsertion（在添加节点时是否移除head）、afterNodeRemoval(在节点移除时更改对应的after、before指针)
其他改动：迭代器实现方式改变，使用了head、tail、after、before指针实现；


#### ConcurrentHashMap
和hashMap的区别  
1.hash函数：在hashMap的基础上与结果与int最大值&，结果其实是一样的，本质无区别  
2.put操作时，定位数组位置使用的unsafe，如果位置没有元素，cas插入；插入失败或者已有元素，synchronized同步当前数组节点，进入while循环，追加链表/树 ；如果定位的节点正在扩容，就会协助进行扩容 
3.两倍扩容(初始16位时是8的阈值扩容位)，每次插入之后都没判断是否需要扩容，扩容条件移除了负载因子的说法，如果桶长度大于了SIZECTL就会进行扩容 OR 协助扩容， 每次扩容后的SIZECTL是原大小的1.5倍
扩容时的sizeCtl高16位是标识位，低16位是正在扩容的线程数目。整个数值是一个负值  
扩容会对数组进行切割，数组大小>>>2如果小于最小值16则每个bound（每个线程一次处理的数量或者每次循环）为16，否则就是该值。控制全局变量transferIndex记录迁移索引，如果元素时ForwardingNode类型也标识该节点已被迁移。  
迁移过程了也使用了synchronized防止put  
4.在1.7版本中使用了分段所机制segment，内部有个segment数组，定位具体的segment，加锁处理~   
5.size方法内部是使用了LongAddr机制，使用内部类CounterCell计数，但是线程不安全


